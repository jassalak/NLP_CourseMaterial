{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda update --all -y \n",
    "#!conda install -n python3 -y -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -n python3 -y -c conda-forge gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.80168545\n",
      "dog banana 0.24327643\n",
      "cat dog 0.80168545\n",
      "cat cat 1.0\n",
      "cat banana 0.28154364\n",
      "banana dog 0.24327643\n",
      "banana cat 0.28154364\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#nlp = spacy.load('en')\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')  # make sure to use larger model!\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog bus 0.2119323\n",
      "dog car 0.3562916\n",
      "dog freight 0.119581945\n",
      "dog arachnoid 0.20180644\n",
      "dog cyst 0.21237248\n",
      "dog banana 0.24327643\n",
      "bus dog 0.2119323\n",
      "bus bus 1.0\n",
      "bus car 0.48169604\n",
      "bus freight 0.3971185\n",
      "bus arachnoid 0.065047614\n",
      "bus cyst 0.037279684\n",
      "bus banana 0.19779922\n",
      "car dog 0.3562916\n",
      "car bus 0.48169604\n",
      "car car 1.0\n",
      "car freight 0.37210107\n",
      "car arachnoid 0.10261742\n",
      "car cyst 0.050885182\n",
      "car banana 0.16172662\n",
      "freight dog 0.119581945\n",
      "freight bus 0.3971185\n",
      "freight car 0.37210107\n",
      "freight freight 1.0\n",
      "freight arachnoid 0.07998085\n",
      "freight cyst 0.017435856\n",
      "freight banana 0.07948214\n",
      "arachnoid dog 0.20180644\n",
      "arachnoid bus 0.065047614\n",
      "arachnoid car 0.10261742\n",
      "arachnoid freight 0.07998085\n",
      "arachnoid arachnoid 1.0\n",
      "arachnoid cyst 0.534446\n",
      "arachnoid banana 0.07937222\n",
      "cyst dog 0.21237248\n",
      "cyst bus 0.037279684\n",
      "cyst car 0.050885182\n",
      "cyst freight 0.017435856\n",
      "cyst arachnoid 0.534446\n",
      "cyst cyst 1.0\n",
      "cyst banana 0.048349928\n",
      "banana dog 0.24327643\n",
      "banana bus 0.19779922\n",
      "banana car 0.16172662\n",
      "banana freight 0.07948214\n",
      "banana arachnoid 0.07937222\n",
      "banana cyst 0.048349928\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'dog bus car freight arachnoid cyst banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen', 'QUEEN', 'queen', 'King', 'KING', 'king', 'KIng', 'MAHARAJAS', 'maharajas', 'Kings', 'princes', 'KINGS', 'Sultans', 'kumbia', 'PRINCES', 'Princes', 'kings', 'SULTANS', 'Maharajas', 'sultans', 'Empresses', 'queens', 'QUEENS', 'empresses', 'duchesses', 'Queens', 'Prince', 'commoner', 'highness', 'HIGHNESS', 'PRINCE', 'prince', 'Sultan', 'Highness', 'SULTAN', 'Commoner', 'COMMONER', 'sultan', 'lord', 'Lord', 'LORD', 'Enthroned', 'Coronation', 'KINGLY', 'THRONE', 'SCEPTER', 'sceptre', 'consort', 'PRETENDER', 'CONSORT']\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    " \n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    " \n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "queen = nlp.vocab['queen'].vector\n",
    "king = nlp.vocab['king'].vector\n",
    " \n",
    "# We now need to find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "maybe_king = man - woman + queen\n",
    "computed_similarities = []\n",
    " \n",
    "for word in nlp.vocab:\n",
    "    # Ignore words without vectors\n",
    "    if not word.has_vector:\n",
    "        continue\n",
    " \n",
    "    similarity = cosine_similarity(maybe_king, word.vector)\n",
    "    computed_similarities.append((word, similarity))\n",
    " \n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "print([w[0].text for w in computed_similarities[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
